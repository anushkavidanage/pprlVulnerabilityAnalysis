# vulnerability.py - Module that implements several vulnerability tests for 
# plaintext and encoded data
#
# July 2020

# Anushka Vidanage, Peter Christen, Thilina Ranbaduge, and Rainer Schnell
#
# Contact: anushka.vidanage@anu.edu.au
#
# Research School of Computer Science, The Australian National University,
# Canberra, ACT, 2601
# -----------------------------------------------------------------------------
#
# Copyright 2020 Australian National University and others.
# All Rights reserved.
#
# -----------------------------------------------------------------------------
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# =============================================================================

import math
import itertools
import numpy
import time
import collections

import hashlib  # A standard Python library
import random   # For random hashing

import bitarray  # Efficient bit-arrays, available from:
                 # https://pypi.org/project/bitarray/

class PlaintextVulnerability():
  """Assessing plaintext vulnerability for different sensitive
     databases before they are being encoded.
  """
  
  # ---------------------------------------------------------------------------

  def __init__(self, tolerance_val, min_num_val, attr_num_list, normalise=False):
    
    """Initialise the PlaintextVulnerability class by providing the required
       parameters.

       Input arguments:
         - hash_funct1, hash_funct2  Two hash functions.
         - bf_len                    The length in bits of the Bloom filters
                                     to be generated.
         - num_hash_funct            The number of hash functions to be used.
         - get_q_gram_pos            A flag, if set to True then the bit
                                     positions of where q-grams are hash into
                                     are returned in a dictionary.

       Output:
         - This method does not return anything.
    """

    # Initialise the class variables
    #
    self.tolerance_val = tolerance_val # epsilon value for the difference 
                                       # threshold
    self.min_num_val = min_num_val # k value for the number of similar values
                                   # threshold
    
    assert tolerance_val >= 0, tolerance_val
    assert min_num_val >= 0, min_num_val
    
    self.attr_num_list = attr_num_list
    self.normalise = normalise
    
  # ---------------------------------------------------------------------------
    
  def calc_freq_vulner(self, plain_val_dict):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    attr_num_list = self.attr_num_list
    normalise = self.normalise
    
    all_val_freq_dict = {}
    
    for rec_id, rec_val_dict in plain_val_dict.iteritems():
      
      for attr_num, val_set in rec_val_dict.iteritems():
        
        if(attr_num == 'rec'):
          plain_val_freq_dict = all_val_freq_dict.get(attr_num, {})
          plain_val_freq_dict[val_set] = plain_val_freq_dict.get(val_set, 0) + 1
          all_val_freq_dict[attr_num] = plain_val_freq_dict
          
        else:
          if(len(val_set) == 0 or val_set == ' '):
            continue
          for plain_val in val_set:
            plain_val_freq_dict = all_val_freq_dict.get(attr_num, {})
            plain_val_freq_dict[plain_val] = plain_val_freq_dict.get(plain_val, 0) + 1
            all_val_freq_dict[attr_num] = plain_val_freq_dict
            
    if(normalise == True):
      all_val_freq_dict_norm = min_max_normalise(all_val_freq_dict, 'freq')
    
    
    # A dictionary with vulnerable plain-text values
    plain_val_vul_dict = {}
    
    for attr_num in all_val_freq_dict.keys():
      
      plain_val_freq_dict = all_val_freq_dict[attr_num]
      #sorted_plain_val_freq_list = sorted(plain_val_freq_dict.items(), 
      #                              key = lambda t: t[1], reverse=True)
      
      #print '  Before dict size:', len(plain_val_freq_dict)
      print ' Attribute index:', attr_num
      
      num_unique_val = len(plain_val_freq_dict.keys())
      
      if(tolerance_val > 0):
        
        all_freq_val_list = plain_val_freq_dict.values()
        min_val = min(all_freq_val_list)
        max_val = max(all_freq_val_list)
        
        new_tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
        new_tolerance_val = int(round(new_tolerance_val))
        
        print ' - Tolerance value: %d (min: %d max: %d)' %(new_tolerance_val, min_val, max_val)
      else:
        new_tolerance_val = tolerance_val
      
      
      inverted_freq_dict = {}
      
      for plain_val, freq in plain_val_freq_dict.iteritems():
        
        sim_freq_val_set = inverted_freq_dict.get(freq, set())
        sim_freq_val_set.add(plain_val)
        inverted_freq_dict[freq] = sim_freq_val_set
      
      print ' - Original/ inverted-index dict sizes: (%d / %d)' \
                                 %(len(plain_val_freq_dict), len(inverted_freq_dict))
      print
      
      plain_val_vul_list = []  
      
      for freq, val_set in inverted_freq_dict.iteritems():
        
        if(len(val_set) >= min_num_val):
          continue
        
        sim_val_set = val_set.copy()
        
        for freq_range_val in range(freq-new_tolerance_val, freq+new_tolerance_val+1):
          if(freq_range_val == freq):
            continue
          
          if(freq_range_val in inverted_freq_dict):
            sim_val_set = sim_val_set.union(inverted_freq_dict[freq_range_val])
          
          if(len(sim_val_set) >= min_num_val):
            break
        
        if(len(sim_val_set) <= (min_num_val - 1)):
          
          for plain_val in val_set:
            
            if(normalise == True):
              plain_val_freq_dict_norm = all_val_freq_dict_norm[attr_num]
              norm_freq = plain_val_freq_dict_norm[plain_val]
              plain_val_vul_list.append((plain_val,norm_freq))
            else:
              plain_val_vul_list.append((plain_val,freq))
        
      plain_val_vul_dict[attr_num] = (plain_val_vul_list, num_unique_val)
    
    return plain_val_vul_dict
  
  # ---------------------------------------------------------------------------
  
  def calc_len_vulner(self, plain_val_dict):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    attr_num_list = self.attr_num_list
    normalise = self.normalise
    
    all_val_len_dict = {}
    
    for rec_id, rec_val_dict in plain_val_dict.iteritems():
      
      for attr_num, val_set in rec_val_dict.iteritems():
        
        if(attr_num == 'rec'):
          plain_val_len = len(val_set)
          val_len_dict = all_val_len_dict.get(attr_num, {})
          same_len_val_set = val_len_dict.get(plain_val_len, set())
          same_len_val_set.add(val_set)
          val_len_dict[plain_val_len] = same_len_val_set
          
          all_val_len_dict[attr_num] = val_len_dict
          
        else:
          for plain_val in val_set:
          
            plain_val_len = len(plain_val)
            val_len_dict = all_val_len_dict.get(attr_num, {})
            same_len_val_set = val_len_dict.get(plain_val_len, set())
            same_len_val_set.add(plain_val)
            val_len_dict[plain_val_len] = same_len_val_set
          
            all_val_len_dict[attr_num] = val_len_dict
    
    if(normalise == True):
      all_val_len_dict_norm, val_norm_val_dict = \
          min_max_normalise(all_val_len_dict, 'len')
    
    
    # A dictionary with vulnerable plain-text values
    plain_val_vul_dict = {}
    
    for attr_num in all_val_len_dict.keys():
      
      plain_val_len_dict = all_val_len_dict[attr_num]
      
      all_unique_val_set = set()
      for plain_val_set in plain_val_len_dict.values():
        all_unique_val_set = all_unique_val_set.union(plain_val_set)
        
      num_unique_val = len(all_unique_val_set)
      
      print ' Attribute index:', attr_num
      
      if(tolerance_val > 0):
        all_len_val_list = plain_val_len_dict.keys()
        min_val = min(all_len_val_list)
        max_val = max(all_len_val_list)
        
        new_tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
        new_tolerance_val = int(round(new_tolerance_val))
        
        print ' - Tolerance value: %d (min: %d max: %d)' %(new_tolerance_val, min_val, max_val)
        print
      else:
        new_tolerance_val = tolerance_val
      
      
      plain_val_vul_list = []  
      
      for val_len, val_set in plain_val_len_dict.iteritems():
        
        if(len(val_set) >= min_num_val):
          continue
        
        sim_val_set = val_set.copy()
        
        for len_range_val in range(val_len-new_tolerance_val, val_len+new_tolerance_val+1):
          if(len_range_val == val_len):
            continue
          
          if(len_range_val in plain_val_len_dict):
            sim_val_set = sim_val_set.union(plain_val_len_dict[len_range_val])
          
          if(len(sim_val_set) >= min_num_val):
            break
        
        if(len(sim_val_set) <= (min_num_val - 1)):
          
          for plain_val in val_set:
            
            if(normalise == True):
              norm_len = val_norm_val_dict[val_len]
              plain_val_vul_list.append((plain_val,norm_len))
            else:
              plain_val_vul_list.append((plain_val, val_len))
        
      plain_val_vul_dict[attr_num] = (plain_val_vul_list, num_unique_val)
    
    return plain_val_vul_dict
  
  # ---------------------------------------------------------------------------
  
  def calc_cooccur_vulner(self, plain_val_dict, cooccur_type, comb_len = 2):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    attr_num_list = self.attr_num_list
    normalise = self.normalise
    
    all_val_comb_freq_dict = {}
    
    for rec_id, rec_val_dict in plain_val_dict.iteritems():
      
      if(cooccur_type == 'rec'):
        
        all_val_set = set()
        for attr_num, val_set in rec_val_dict.iteritems():
          all_val_set = all_val_set.union(val_set)
        
        all_val_comb = itertools.combinations(all_val_set, comb_len)
        
        for val_comb in all_val_comb:
          val_comb = tuple(sorted(val_comb))
          
          val_comb_dict = all_val_comb_freq_dict.get('rec', {})
          val_comb_dict[val_comb] = val_comb_dict.get(val_comb, 0) + 1
          all_val_comb_freq_dict['rec'] = val_comb_dict
        
      elif(cooccur_type == 'attr'):
        
        for attr_num, val_set in rec_val_dict.iteritems():
          all_val_comb = itertools.combinations(val_set, comb_len)
        
          for val_comb in all_val_comb:
            val_comb = tuple(sorted(val_comb))
        
            val_comb_dict = all_val_comb_freq_dict.get(attr_num, {})
            val_comb_dict[val_comb] = val_comb_dict.get(val_comb, 0) + 1
            all_val_comb_freq_dict[attr_num] = val_comb_dict
    
    if(normalise == True):
      all_val_comb_freq_dict_norm = min_max_normalise(all_val_comb_freq_dict, 'freq')
    
    # A dictionary with vulnerable plain-text values
    plain_val_vul_dict = {}
    
    if(cooccur_type == 'rec'):
      
      val_comb_freq_dict = all_val_comb_freq_dict['rec']
      
      #sorted_plain_val_comb_freq_list = sorted(val_comb_freq_dict.items(), 
      #                            key = lambda t: t[1], reverse=True)
      
      num_unique_val_pairs = len(val_comb_freq_dict.keys())
      
      print ' Attribute index: rec'
      
      if(tolerance_val > 0):
        all_freq_val_list = val_comb_freq_dict.values()
        min_val = min(all_freq_val_list)
        max_val = max(all_freq_val_list)
        
        new_tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
        new_tolerance_val = int(round(new_tolerance_val))
        
        print ' - Tolerance value: %d (min: %d max: %d)' %(new_tolerance_val, min_val, max_val)
      else:
        new_tolerance_val = tolerance_val
      
      
      inverted_freq_dict = {}
      
      for plain_val_comb, freq in val_comb_freq_dict.iteritems():
        
        sim_freq_val_comb_set = inverted_freq_dict.get(freq, set())
        sim_freq_val_comb_set.add(plain_val_comb)
        inverted_freq_dict[freq] = sim_freq_val_comb_set
      
      print ' - Original/ inverted-index dict sizes: (%d / %d)' \
                                 %(len(val_comb_freq_dict), len(inverted_freq_dict))
      print
      
      plain_val_vul_list = []  
      
      for freq, val_comb_set in inverted_freq_dict.iteritems():
        
        if(len(val_comb_set) >= min_num_val):
          continue
        
        sim_val_comb_set = val_comb_set.copy()
        
        for freq_range_val in range(freq-new_tolerance_val, freq+new_tolerance_val+1):
          if(freq_range_val == freq):
            continue
          
          if(freq_range_val in inverted_freq_dict):
            sim_val_comb_set = sim_val_comb_set.union(inverted_freq_dict[freq_range_val])
          
          if(len(sim_val_comb_set) >= min_num_val):
            break
        
        if(len(sim_val_comb_set) <= (min_num_val - 1)):
          
          for plain_val_comb in val_comb_set:
            if(normalise == True):
              val_comb_freq_dict_norm = all_val_comb_freq_dict_norm['rec']
              freq_norm = val_comb_freq_dict_norm[plain_val_comb]
              plain_val_vul_list.append((plain_val_comb,freq_norm))
            else:
              plain_val_vul_list.append((plain_val_comb,freq))
        
      plain_val_vul_dict['rec'] = (plain_val_vul_list, num_unique_val_pairs)
    
    elif(cooccur_type == 'attr'): # Anushka: Below is not updated to new funtion
    
      for attr_num in all_val_comb_freq_dict.keys():
      
        val_comb_dict = all_val_comb_freq_dict[attr_num]
        #sorted_plain_val_comb_freq_list = sorted(val_comb_dict.items(), 
        #                          key = lambda t: t[0], reverse=True)
        
        num_unique_val_pairs = len(val_comb_dict.keys())
        
        print ' Attribute index:', attr_num
      
        if(tolerance_val > 0):
          all_freq_val_list = val_comb_dict.values()
          min_val = min(all_freq_val_list)
          max_val = max(all_freq_val_list)
        
          new_tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
          new_tolerance_val = int(round(new_tolerance_val))
        
          print ' - Tolerance value: %d (min: %d max: %d)' %(new_tolerance_val, min_val, max_val)
        else:
          new_tolerance_val = tolerance_val
      
      
        inverted_freq_dict = {}
      
        for plain_val_comb, freq in val_comb_dict.iteritems():
        
          sim_freq_val_comb_set = inverted_freq_dict.get(freq, set())
          sim_freq_val_comb_set.add(plain_val_comb)
          inverted_freq_dict[freq] = sim_freq_val_comb_set
      
        print ' - Original/ inverted-index dict sizes: (%d / %d)' \
                          %(len(val_comb_dict), len(inverted_freq_dict))
        print
        
        
        plain_val_vul_list = []  
      
        for freq, val_comb_set in inverted_freq_dict.iteritems():
        
          if(len(val_comb_set) >= min_num_val):
            continue
        
          sim_val_comb_set = val_comb_set.copy()
        
          for freq_range_val in range(freq-new_tolerance_val, freq+new_tolerance_val+1):
            if(freq_range_val == freq):
              continue
          
            if(freq_range_val in inverted_freq_dict):
              sim_val_comb_set = sim_val_comb_set.union(inverted_freq_dict[freq_range_val])
          
            if(len(sim_val_comb_set) >= min_num_val):
              break
        
          if(len(sim_val_comb_set) <= (min_num_val - 1)):
          
            for plain_val_comb in val_comb_set:
              
              if(normalise == True):
                val_comb_freq_dict_norm = all_val_comb_freq_dict_norm[attr_num]
                freq_norm = val_comb_freq_dict_norm[plain_val_comb]
                plain_val_vul_list.append((plain_val_comb,freq_norm))
              else:
                plain_val_vul_list.append((plain_val_comb,freq))
        
        plain_val_vul_dict[attr_num] = (plain_val_vul_list, num_unique_val_pairs)
    
    return plain_val_vul_dict
  
  # ---------------------------------------------------------------------------
  
  def calc_sim_vulner_old(self, plain_sim_dict):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    attr_num_list = self.attr_num_list
      
    # Calculate the vulneravbility of values
    plain_val_vul_dict = {}
   
    for attr_num, val_pair_sim_dict in plain_sim_dict.iteritems():
    
      plain_val_vul_list = []
    
      print 'Attribute number: ', attr_num
    
      sorted_sim_val_list = sorted(val_pair_sim_dict.items(), 
                                   key = lambda t: t[1], reverse=True)
      
      num_unique_val_pairs = len(sorted_sim_val_list)
      
      if(tolerance_val > 0):
        all_sim_val_list = val_pair_sim_dict.values()
        min_val = min(all_sim_val_list)
        max_val = max(all_sim_val_list)
        
        new_tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
      
        
      print 'Attribute Number:', attr_num
      for val_pair, val_sim in sorted_sim_val_list[:4]:
        print '  Plain-text value/ similarity: %s / %.4f' %(val_pair, val_sim)
    
      print '  ...'
  
      for val_pair, val_sim in sorted_sim_val_list[-4:]:
        print '  Plain-text value/ similarity: %s / %.4f' %(val_pair, val_sim)

    
      start_index = 0
    
      while(len(sorted_sim_val_list) > start_index):
      
        val_pair, val_sim = sorted_sim_val_list[start_index]
    
        similar_val_sim_dict = {}

        for next_val_pair, next_val_sim in sorted_sim_val_list[start_index+1:]:
      
          sim_diff = val_sim - next_val_sim
       
          if(sim_diff <= tolerance_val):
            similar_val_sim_dict[next_val_pair] = next_val_sim
            start_index += 1
         
          else:
            break
    
        if(len(similar_val_sim_dict) <= (min_num_val - 1)):
      
          plain_val_vul_list.append((val_pair, val_sim))
       
          if(len(similar_val_sim_dict) > 0):
            for s_val_pair, s_val_sim in similar_val_sim_dict.iteritems():
              plain_val_vul_list.append((s_val_pair, s_val_sim))
    
        start_index += 1
    
      plain_val_vul_dict[attr_num] = (plain_val_vul_list, num_unique_val_pairs)
    
    return plain_val_vul_dict
  
  #---------------------------------------------------------
  
  def calc_sim_vulner(self, plain_sim_dict):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    attr_num_list = self.attr_num_list
    
    lim_exceed_txt = 'min_num_val_reached'
      
    # Calculate the vulneravbility of values
    plain_val_vul_dict = {}
   
    for attr_num, val_pair_sim_dict in plain_sim_dict.iteritems():
    
      plain_val_vul_list = []
    
      print 'Attribute index: ', attr_num
      print
      
      inverted_sim_dict = {}
      removed_sim_set = set()
      
      for val_pair, pair_sim in val_pair_sim_dict.iteritems():
        
        pair_sim = round(pair_sim, 10)
        
        sim_plain_val_pair_set = inverted_sim_dict.get(pair_sim, set())
        
        if(lim_exceed_txt in sim_plain_val_pair_set):
          continue
        
        sim_plain_val_pair_set.add(val_pair)
        
        if(len(sim_plain_val_pair_set) > (min_num_val - 1)):
          inverted_sim_dict[pair_sim] = set([lim_exceed_txt])
        else:
          inverted_sim_dict[pair_sim] = sim_plain_val_pair_set
        
        #=======================================================================
        # if('removed' in sim_plain_val_pair_set):
        #   continue
        # else:
        #   sim_plain_val_pair_set.add(val_pair)
        # 
        #   if(len(sim_plain_val_pair_set) >= min_num_val):
        #     inverted_sim_dict[pair_sim] = set(['removed'])
        #   else:
        #     inverted_sim_dict[pair_sim] = sim_plain_val_pair_set
        #=======================================================================
      
      print ' - Original/ inverted-index dict sizes: (%d / %d)' \
                                 %(len(val_pair_sim_dict), len(inverted_sim_dict))
      
      sorted_sim_val_list = sorted(inverted_sim_dict.keys(), reverse=True)
      
      if(tolerance_val > 0):
        all_sim_val_list = val_pair_sim_dict.values()
        min_val = min(all_sim_val_list)
        max_val = max(all_sim_val_list)
        
        new_tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
        print ' - Tolerance value: %d (min: %d max: %d)' %(new_tolerance_val, min_val, max_val)
        print
        
      else:
        new_tolerance_val = tolerance_val  
        
      num_unique_val_pairs = len(val_pair_sim_dict.values())
      
      org_sim_val_dict = inverted_sim_dict.copy()
      
      for i, val_sim in enumerate(sorted_sim_val_list):

        org_val_pair_set = org_sim_val_dict[val_sim]
        val_pair_set = inverted_sim_dict[val_sim]
        
        #if(len(val_pair_set) >= min_num_val):
        #  continue
        
        sim_val_pair_set = val_pair_set.copy()
        
        for next_val_sim in sorted_sim_val_list[i+1:]:
          org_next_val_pair_set = org_sim_val_dict[next_val_sim]
          next_val_pair_set = inverted_sim_dict[next_val_sim]
          sim_diff = val_sim - next_val_sim
       
          if(sim_diff <= new_tolerance_val):
            
            if(lim_exceed_txt in org_next_val_pair_set):
              sim_val_pair_set = set([lim_exceed_txt])
            else:
              if(lim_exceed_txt not in sim_val_pair_set):
                sim_val_pair_set = sim_val_pair_set.union(org_next_val_pair_set)
                
                if(len(sim_val_pair_set) > (min_num_val - 1)):
                  sim_val_pair_set = set([lim_exceed_txt])
              
              
              if(lim_exceed_txt not in next_val_pair_set):
                next_val_pair_set = next_val_pair_set.union(org_val_pair_set)
                if(len(next_val_pair_set) > (min_num_val - 1)):
                  inverted_sim_dict[next_val_sim] = set([lim_exceed_txt])
                else:
                  inverted_sim_dict[next_val_sim] = next_val_pair_set
          
          else:
            break
        
        inverted_sim_dict[val_sim] = sim_val_pair_set
        
      plain_val_vul_list = []
      
      for sim_val, similar_val_pair_set in inverted_sim_dict.iteritems():
        
        if(lim_exceed_txt not in similar_val_pair_set):
        
          if(len(similar_val_pair_set) <= (min_num_val - 1)):
            org_val_pair_set = org_sim_val_dict[sim_val]
          
            for plain_val_pair in org_val_pair_set:
              plain_val_vul_list.append((plain_val_pair, sim_val))

      plain_val_vul_dict[attr_num] = (plain_val_vul_list, num_unique_val_pairs)

    return plain_val_vul_dict
  
  # ---------------------------------------------------------------------------
  
  def calc_neigh_vulner(self, sim_neigh_blck_dict, sim_neigh_vec_dict):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    attr_num_list = self.attr_num_list
    
    tolerance_val = float(tolerance_val)/100
    
    lim_exceed_txt = 'min_num_val_reached'
    
    # Calculate the vulneravbility of values
    plain_val_vul_dict = {}
  
    for attr_num, attr_sim_neigh_blck_dict in sim_neigh_blck_dict.iteritems():
      
      uniqe_val_set = set()
      vul_val_dict = {}
      
      print 'Attribute index: ', attr_num
    
      attr_sim_neigh_vec_dict = sim_neigh_vec_dict[attr_num]
    
      for blck_key_set in attr_sim_neigh_blck_dict.values():
        
        uniqe_val_set = uniqe_val_set.union(blck_key_set)
        
        all_key_pairs = itertools.combinations(blck_key_set, 2)
      
        for val_key1, val_key2 in all_key_pairs:
          
          sim_neigh_feat_vec1 = attr_sim_neigh_vec_dict[val_key1]
          sim_neigh_feat_vec2 = attr_sim_neigh_vec_dict[val_key2]
          
          # Calculate the Cosine similarity beween the featue vectors
          #
          vec_len1 = math.sqrt(numpy.dot(sim_neigh_feat_vec1, sim_neigh_feat_vec1))
          vec_len2 = math.sqrt(numpy.dot(sim_neigh_feat_vec2, sim_neigh_feat_vec2))
          cosine = numpy.dot(sim_neigh_feat_vec1,sim_neigh_feat_vec2) / vec_len1 / vec_len2
          cos_distance = math.acos(min(cosine,1.0)) / math.pi
      
          if(cos_distance <= tolerance_val):
            sim_val_set1 = vul_val_dict.get(val_key1, set())
            sim_val_set2 = vul_val_dict.get(val_key2, set())
            
            
            if(lim_exceed_txt not in sim_val_set1):
              sim_val_set1.add(val_key2)
              
              if(len(sim_val_set1) > (min_num_val - 1)):
                sim_val_set1 = set([lim_exceed_txt])
            
            if(lim_exceed_txt not in sim_val_set2):
              sim_val_set2.add(val_key1)
              
              if(len(sim_val_set2) > (min_num_val - 1)):
                sim_val_set2 = set([lim_exceed_txt])
            
            vul_val_dict[val_key1] = sim_val_set1
            vul_val_dict[val_key2] = sim_val_set2
          
          else:
            if(val_key1 not in vul_val_dict):
              vul_val_dict[val_key1] = set()
            
            if(val_key2 not in vul_val_dict):
              vul_val_dict[val_key2] = set()
        
      plain_val_vul_list = []
      
      for val_key, sim_val_set in vul_val_dict.iteritems():
        
        if(lim_exceed_txt not in sim_val_set):
          
          if(len(sim_val_set) <= (min_num_val - 1)):
            sim_neigh_feat_vec = attr_sim_neigh_vec_dict[val_key]
            plain_val_vul_list.append((val_key, sim_neigh_feat_vec))
        
      num_unique_val = len(uniqe_val_set)  
      plain_val_vul_dict[attr_num] = (plain_val_vul_list, num_unique_val)
    
    
    return plain_val_vul_dict
  
# =============================================================================

class EncodingVulnerability():
  """Assessing encoidng vulnerability for different sensitive
     databases before they are being encoded.
  """
  
  # ---------------------------------------------------------------------------

  def __init__(self, tolerance_val, min_num_val, enc_method, normalise=False):
    
    """Initialise the PlaintextVulnerability class by providing the required
       parameters.

       Input arguments:
         - hash_funct1, hash_funct2  Two hash functions.
         - bf_len                    The length in bits of the Bloom filters
                                     to be generated.
         - num_hash_funct            The number of hash functions to be used.
         - get_q_gram_pos            A flag, if set to True then the bit
                                     positions of where q-grams are hash into
                                     are returned in a dictionary.

       Output:
         - This method does not return anything.
    """

    # Initialise the class variables
    #
    self.tolerance_val = tolerance_val # epsilon value for the difference 
                                       # threshold
    self.min_num_val = min_num_val # k value for the number of similar values
                                   # threshold
    self.enc_method = enc_method
    
    self.normalise = normalise
    
    assert tolerance_val >= 0, tolerance_val
    assert min_num_val >= 0, min_num_val
    assert enc_method in ['bf', 'tmh', '2sh', 'mmk', 'slk']
    
  # ---------------------------------------------------------------------------
  
  def calc_freq_vulner(self, encode_val_dict):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    normalise = self.normalise
    
    all_enc_val_freq_dict = {}
    
    for rec_id, attr_enc_val_dict in encode_val_dict.iteritems():
      
      for attr_num, enc_val in attr_enc_val_dict.iteritems():
        if(enc_method in ['bf', 'tmh']):
          enc_val_key = enc_val.to01()
        else:
          enc_val_key = enc_val
        
        if(len(enc_val) > 0 and enc_val != ' '):
          enc_val_freq_dict = all_enc_val_freq_dict.get(attr_num, {})
          enc_val_freq_dict[enc_val_key] = enc_val_freq_dict.get(enc_val_key, 0) + 1
          all_enc_val_freq_dict[attr_num] = enc_val_freq_dict    
    
    if(normalise == True):
      all_enc_val_freq_dict_norm = min_max_normalise(all_enc_val_freq_dict, 'freq')
    
    # A dictionary with vulnerable plain-text values
    enc_val_vul_dict = {}
    
    for attr_num in all_enc_val_freq_dict.keys():
      
      enc_val_freq_dict = all_enc_val_freq_dict[attr_num]
      #sorted_enc_val_freq_list = sorted(enc_val_freq_dict.items(), 
      #                              key = lambda t: t[1], reverse=True)
      
      print ' Attribute index:', attr_num
      
      num_unique_val = len(enc_val_freq_dict.keys())
      
      if(tolerance_val > 0):
        all_freq_val_list = enc_val_freq_dict.values()
        min_val = min(all_freq_val_list)
        max_val = max(all_freq_val_list)
        
        new_tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
        new_tolerance_val = int(round(new_tolerance_val))
        
        print ' - Tolerance value: %d (min: %d max: %d)' %(new_tolerance_val, min_val, max_val)
      else:
        new_tolerance_val = tolerance_val
      
      
      inverted_freq_dict = {}
      
      for enc_val, freq in enc_val_freq_dict.iteritems():
        
        sim_freq_val_set = inverted_freq_dict.get(freq, set())
        sim_freq_val_set.add(enc_val)
        inverted_freq_dict[freq] = sim_freq_val_set
      
      print ' - Original/ inverted-index dict sizes: (%d / %d)' \
                                 %(len(enc_val_freq_dict), len(inverted_freq_dict))
      print
      
      enc_val_vul_list = []  
      
      for freq, val_set in inverted_freq_dict.iteritems():
        
        if(len(val_set) >= min_num_val):
          continue
        
        sim_val_set = val_set.copy()
        
        for freq_range_val in range(freq-new_tolerance_val, freq+new_tolerance_val+1):
          if(freq_range_val == freq):
            continue
          
          if(freq_range_val in inverted_freq_dict):
            sim_val_set = sim_val_set.union(inverted_freq_dict[freq_range_val])
          
          if(len(sim_val_set) >= min_num_val):
            break
        
        if(len(sim_val_set) <= (min_num_val - 1)):
          
          for enc_val in val_set:
            
            if(normalise == True):
              enc_val_freq_dict_norm = all_enc_val_freq_dict_norm[attr_num]
              norm_freq = enc_val_freq_dict_norm[enc_val]
              enc_val_vul_list.append((enc_val,norm_freq))
            else:
              enc_val_vul_list.append((enc_val,freq))
        
      enc_val_vul_dict[attr_num] = (enc_val_vul_list, num_unique_val)
    
    return enc_val_vul_dict
  
  # ---------------------------------------------------------------------------
  
  def calc_freq_assign(self, enc_val_vul_dict, plain_val_vul_dict, 
                       enc_val_q_tuple_dict):
    
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    
    tolerance_val = float(tolerance_val)/100
    
    enc_assign_val_dict = {}
    
    for attr_num in enc_val_vul_dict.keys():
      
      if(enc_method in ['mmk', 'slk']):
        attr_q_tuple_dict = enc_val_q_tuple_dict['rec']
      else:
        attr_q_tuple_dict = enc_val_q_tuple_dict[attr_num]
      
      vul_enc_plain_val_list = []
      corr_vul_enc_plain_val_list = []
      
      enc_val_vul_list, enc_num_unique_val = enc_val_vul_dict[attr_num]
      plain_val_vul_list, plain_num_unique_val = plain_val_vul_dict[attr_num]
      
      sorted_enc_val_vul_list = sorted(enc_val_vul_list, key = lambda t:t[1], reverse=True)
      sorted_plain_val_vul_list = sorted(plain_val_vul_list, key = lambda t:t[1], reverse=True)
      
      for enc_val, enc_freq in sorted_enc_val_vul_list:
        
        similar_freq_val_dict = {}
        
        for plain_val, plain_freq in sorted_plain_val_vul_list:
          
          if(abs(enc_freq - plain_freq) <= tolerance_val):
            similar_freq_val_dict[plain_val] = plain_freq
            
          else:
            if(enc_freq - plain_freq > tolerance_val):
              break
        
        if(1 <= len(similar_freq_val_dict) <= (min_num_val - 1)):
          vul_enc_plain_val_list.append((enc_val, enc_freq, similar_freq_val_dict))
          
          enc_plain_val_set = attr_q_tuple_dict[enc_val]
          sim_plain_val_set = set(similar_freq_val_dict.keys())
          
          #print enc_plain_val
          #print sim_plain_val_set
          
          if(len(enc_plain_val_set & sim_plain_val_set) > 0):
            corr_vul_enc_plain_val_list.append((enc_val, enc_freq, similar_freq_val_dict))
      
      enc_assign_val_dict[attr_num] = (vul_enc_plain_val_list, corr_vul_enc_plain_val_list,
                                       enc_num_unique_val)
              
    
    return enc_assign_val_dict
  
  # --------------------------------------------------------------------------
    
  def calc_len_vulner(self, encode_val_dict):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    normalise = self.normalise
    
    all_enc_val_len_dict = {}
    
    for rec_id, attr_enc_val_dict in encode_val_dict.iteritems():
      
      for attr_num, enc_val in attr_enc_val_dict.iteritems():
        if(enc_method in ['bf', 'tmh']):
          enc_val_key = enc_val.to01()
          enc_val_len = enc_val.count(1)
        else:
          enc_val_key = enc_val
          enc_val_len = len(enc_val)
        
        enc_val_len_dict = all_enc_val_len_dict.get(attr_num, {})
        same_len_val_set = enc_val_len_dict.get(enc_val_len, set())
        same_len_val_set.add(enc_val_key)
        enc_val_len_dict[enc_val_len] = same_len_val_set
        all_enc_val_len_dict[attr_num] = enc_val_len_dict
           
    if(normalise == True):
      all_enc_val_len_dict_norm, val_norm_val_dict = \
          min_max_normalise(all_enc_val_len_dict, 'len')
      
      
    # A dictionary with vulnerable plain-text values
    enc_val_vul_dict = {}
    
    for attr_num in all_enc_val_len_dict.keys():
      
      enc_val_len_dict = all_enc_val_len_dict[attr_num]
      
      all_unique_val_set = set()
      for enc_val_set in enc_val_len_dict.values():
        all_unique_val_set = all_unique_val_set.union(enc_val_set)
        
      num_unique_val = len(all_unique_val_set)
      
      #sorted_enc_val_len_list = sorted(enc_val_len_dict.items(), 
      #                                 key = lambda t: t[0], reverse=True)
      
      print ' Attribute index:', attr_num
      
      if(tolerance_val > 0):
        all_freq_val_list = enc_val_len_dict.keys()
        min_val = min(all_freq_val_list)
        max_val = max(all_freq_val_list)
        
        new_tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
        new_tolerance_val = int(round(new_tolerance_val))
        
        print ' - Tolerance value: %d (min: %d max: %d)' %(new_tolerance_val, min_val, max_val)
        print
      else:
        new_tolerance_val = tolerance_val
      
      
      enc_val_vul_list = []  
      
      for val_len, val_set in enc_val_len_dict.iteritems():
        
        if(len(val_set) >= min_num_val):
          continue
        
        sim_val_set = val_set.copy()
        
        for len_range_val in range(val_len-new_tolerance_val, val_len+new_tolerance_val+1):
          if(len_range_val == val_len):
            continue
          
          if(len_range_val in enc_val_len_dict):
            sim_val_set = sim_val_set.union(enc_val_len_dict[len_range_val])
          
          if(len(sim_val_set) >= min_num_val):
            break
        
        if(len(sim_val_set) <= (min_num_val - 1)):
          
          for enc_val in val_set:
            if(normalise == True):
              val_len_norm = val_norm_val_dict[val_len]
              enc_val_vul_list.append((enc_val, val_len_norm))
            else:
              enc_val_vul_list.append((enc_val, val_len))
        
      enc_val_vul_dict[attr_num] = (enc_val_vul_list, num_unique_val)
    
    return enc_val_vul_dict
  
  # ---------------------------------------------------------------------------
  
  def calc_len_assign(self, enc_val_vul_dict, plain_val_vul_dict,
                      enc_val_q_tuple_dict):
    
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    
    tolerance_val = float(tolerance_val)/100
    
    enc_assign_val_dict = {}
    
    for attr_num in enc_val_vul_dict.keys():
      
      vul_enc_plain_val_list = []
      corr_vul_enc_plain_val_list = []
      
      attr_q_tuple_dict = enc_val_q_tuple_dict[attr_num]
      
      enc_val_vul_list, enc_num_unique_val = enc_val_vul_dict[attr_num]
      plain_val_vul_list, plain_num_unique_val = plain_val_vul_dict[attr_num]
      
      sorted_enc_val_vul_list = sorted(enc_val_vul_list, key = lambda t:t[1], reverse=True)
      sorted_plain_val_vul_list = sorted(plain_val_vul_list, key = lambda t:t[1], reverse=True)
      
      for enc_val, enc_len in sorted_enc_val_vul_list:
        
        similar_len_val_dict = {}
        
        for plain_val, plain_len in sorted_plain_val_vul_list:
          
          if(abs(enc_len - plain_len) <= tolerance_val):
            similar_len_val_dict[plain_val] = plain_len
            
          else:
            if(enc_len - plain_len > tolerance_val):
              break
        
        if(1 <= len(similar_len_val_dict) <= (min_num_val - 1)):
          vul_enc_plain_val_list.append((enc_val, enc_len, similar_len_val_dict))
          
          enc_plain_val_set = attr_q_tuple_dict[enc_val]
          sim_plain_val_set = set(similar_len_val_dict.keys())
          
          #print 'encode', enc_plain_val_set
          #print 'plain', sim_plain_val_set
          
          if(len(enc_plain_val_set & sim_plain_val_set) > 0):
            corr_vul_enc_plain_val_list.append((enc_val, enc_len, similar_len_val_dict))
      
      enc_assign_val_dict[attr_num] = (vul_enc_plain_val_list, corr_vul_enc_plain_val_list,
                                       enc_num_unique_val)
              
    return enc_assign_val_dict
  
  # ---------------------------------------------------------------------------
  
  def calc_cooccur_vulner(self, encode_val_dict, comb_len = 2):
    
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    normalise = self.normalise
    
    all_val_comb_freq_dict = {}
    enc_val_vul_dict = {}
    
    for rec_id, attr_enc_val_dict in encode_val_dict.iteritems():
      
      all_enc_val_set = set()
      
      for enc_val in attr_enc_val_dict.values():
        if(enc_method in ['bf', 'tmh']):
          enc_val_key = enc_val.to01()
        else:
          enc_val_key = enc_val
        
        all_enc_val_set.add(enc_val_key)
      
      all_val_comb = itertools.combinations(all_enc_val_set, comb_len)
      
      for val_comb in all_val_comb:
        val_comb = tuple(sorted(val_comb))
        
        val_comb_dict = all_val_comb_freq_dict.get('rec', {})
        val_comb_dict[val_comb] = val_comb_dict.get(val_comb, 0) + 1
        all_val_comb_freq_dict['rec'] = val_comb_dict
      
    #print all_val_comb_freq_dict
    
    if(normalise == True):
      all_val_comb_freq_dict_norm = min_max_normalise(all_val_comb_freq_dict, 'cooccur')
    
    val_comb_freq_dict = all_val_comb_freq_dict['rec']
    
    sorted_enc_val_comb_freq_list = sorted(val_comb_freq_dict.items(), 
                                  key = lambda t: t[1], reverse=True)
    
    num_unique_val_pairs = len(val_comb_freq_dict.keys())
      
    print ' Attribute index: rec'
    
    if(tolerance_val > 0):
      all_freq_val_list = val_comb_freq_dict.values()
      min_val = min(all_freq_val_list)
      max_val = max(all_freq_val_list)
      
      new_tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
      new_tolerance_val = int(round(new_tolerance_val))
      
      print ' - Tolerance value: %d (min: %d max: %d)' %(new_tolerance_val, min_val, max_val)
    else:
      new_tolerance_val = tolerance_val
    
    
    inverted_freq_dict = {}
    
    for enc_val_comb, freq in val_comb_freq_dict.iteritems():
      
      sim_freq_val_comb_set = inverted_freq_dict.get(freq, set())
      sim_freq_val_comb_set.add(enc_val_comb)
      inverted_freq_dict[freq] = sim_freq_val_comb_set
    
    print ' - Original/ inverted-index dict sizes: (%d / %d)' \
                               %(len(val_comb_freq_dict), len(inverted_freq_dict))
    print
    
    enc_val_vul_list = []  
    
    for freq, val_comb_set in inverted_freq_dict.iteritems():
      
      if(len(val_comb_set) >= min_num_val):
        continue
      
      sim_val_comb_set = val_comb_set.copy()
      
      for freq_range_val in range(freq-new_tolerance_val, freq+new_tolerance_val+1):
        if(freq_range_val == freq):
          continue
        
        if(freq_range_val in inverted_freq_dict):
          sim_val_comb_set = sim_val_comb_set.union(inverted_freq_dict[freq_range_val])
        
        if(len(sim_val_comb_set) >= min_num_val):
          break
      
      if(len(sim_val_comb_set) <= (min_num_val - 1)):
        
        for enc_val_comb in val_comb_set:
          if(normalise == True):
            val_comb_freq_dict_norm = all_val_comb_freq_dict_norm['rec']
            freq_norm = val_comb_freq_dict_norm[enc_val_comb]
            enc_val_vul_list.append((enc_val_comb,freq_norm))
          else:
            enc_val_vul_list.append((enc_val_comb,freq))
      
    enc_val_vul_dict['rec'] = (enc_val_vul_list, num_unique_val_pairs)
    
    return enc_val_vul_dict
  
  # ---------------------------------------------------------------------------
  
  def calc_cooccur_assign(self, enc_val_vul_dict, plain_val_vul_dict,
                          enc_val_q_tuple_dict):
    
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    
    tolerance_val = float(tolerance_val)/100
    
    enc_assign_val_dict = {}
    
    for attr_num in enc_val_vul_dict.keys():
      
      vul_enc_plain_val_list      = []
      corr_vul_enc_plain_val_list = []
      
      attr_q_tuple_dict = enc_val_q_tuple_dict[attr_num]
      
      enc_val_vul_list, enc_num_unique_val = enc_val_vul_dict[attr_num]
      plain_val_vul_list, plain_num_unique_val = plain_val_vul_dict[attr_num]
      
      sorted_enc_val_vul_list = sorted(enc_val_vul_list, key = lambda t:t[1], reverse=True)
      sorted_plain_val_vul_list = sorted(plain_val_vul_list, key = lambda t:t[1], reverse=True)
      
      for enc_val_pair, enc_freq in sorted_enc_val_vul_list:
        similar_cooccur_val_dict = {}
        
        for plain_val_pair, plain_freq in sorted_plain_val_vul_list:
          if(abs(enc_freq - plain_freq) <= tolerance_val):
            similar_cooccur_val_dict[plain_val_pair] = plain_freq
            
          else:
            if(enc_freq - plain_freq > tolerance_val):
              break
        
        if(1 <= len(similar_cooccur_val_dict) <= (min_num_val - 1)):
          vul_enc_plain_val_list.append((enc_val_pair, enc_freq, 
                                         similar_cooccur_val_dict))
          
          enc_val1 = enc_val_pair[0]
          enc_val2 = enc_val_pair[1]
          
          enc_plain_val_set1 = attr_q_tuple_dict[enc_val1]
          enc_plain_val_set2 = attr_q_tuple_dict[enc_val2]
          
          sim_plain_val_set = set()
          
          for plain_val1, plain_val2 in similar_cooccur_val_dict.keys():
            sim_plain_val_set.add(plain_val1)
            sim_plain_val_set.add(plain_val2)
          
          if(len(enc_plain_val_set1 & sim_plain_val_set) > 0 and
             len(enc_plain_val_set2 & sim_plain_val_set) > 0):
            corr_vul_enc_plain_val_list.append((enc_val_pair, enc_freq, 
                                                similar_cooccur_val_dict))
      
      enc_assign_val_dict[attr_num] = (vul_enc_plain_val_list, corr_vul_enc_plain_val_list,
                                       enc_num_unique_val)
              
    return enc_assign_val_dict
  
  # ---------------------------------------------------------------------------
  
  def calc_sim_vulner(self, encode_sim_dict):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    
    lim_exceed_txt = 'min_num_val_reached'
      
    # Calculate the vulneravbility of values
    enc_val_vul_dict = {}
   
    for attr_num, enc_pair_sim_dict in encode_sim_dict.iteritems():
    
      enc_val_vul_list = []
    
      print 'Attribute index: ', attr_num
    
      #sorted_sim_val_list = sorted(enc_pair_sim_dict.items(), 
      #                             key = lambda t: t[1], reverse=True)
      
      num_unique_val_pairs = len(enc_pair_sim_dict.keys())
      
      inverted_sim_dict = {}
      
      for val_pair, pair_sim in enc_pair_sim_dict.iteritems():
        
        pair_sim = round(pair_sim, 10)
        
        sim_enc_val_pair_set = inverted_sim_dict.get(pair_sim, set())
        
        if(lim_exceed_txt in sim_enc_val_pair_set):
          continue
        
        sim_enc_val_pair_set.add(val_pair)
        
        if(len(sim_enc_val_pair_set) > (min_num_val - 1)):
          inverted_sim_dict[pair_sim] = set([lim_exceed_txt])
        else:
          inverted_sim_dict[pair_sim] = sim_enc_val_pair_set
      
      print ' - Original/ inverted-index dict sizes: (%d / %d)' \
                                 %(len(enc_pair_sim_dict), len(inverted_sim_dict))
      
      sorted_sim_val_list = sorted(inverted_sim_dict.keys(), reverse=True)
      
      if(tolerance_val > 0):
        all_freq_val_list = enc_pair_sim_dict.values()
        min_val = min(all_freq_val_list)
        max_val = max(all_freq_val_list)
        
        new_tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
        print ' - Tolerance value: %d (min: %d max: %d)' %(new_tolerance_val, min_val, max_val)
        print
        
      else:
        new_tolerance_val = tolerance_val
      
      org_sim_val_dict = inverted_sim_dict.copy()
      
      for i, val_sim in enumerate(sorted_sim_val_list):

        org_val_pair_set = org_sim_val_dict[val_sim]
        val_pair_set = inverted_sim_dict[val_sim]
        
        #if(len(val_pair_set) >= min_num_val):
        #  continue
        
        #if(lim_exceed_txt in val_pair_set):
        #  continue
        
        sim_val_pair_set = val_pair_set.copy()
        
        for next_val_sim in sorted_sim_val_list[i+1:]:
          org_next_val_pair_set = org_sim_val_dict[next_val_sim]
          next_val_pair_set = inverted_sim_dict[next_val_sim]
          sim_diff = val_sim - next_val_sim
       
          if(sim_diff <= new_tolerance_val):
            
            if(lim_exceed_txt in org_next_val_pair_set):
              sim_val_pair_set = set([lim_exceed_txt])
            else:
              if(lim_exceed_txt not in sim_val_pair_set):
                sim_val_pair_set = sim_val_pair_set.union(org_next_val_pair_set)
              
                if(len(sim_val_pair_set) > (min_num_val - 1)):
                  sim_val_pair_set = set([lim_exceed_txt])
              
              if(lim_exceed_txt not in next_val_pair_set):
                next_val_pair_set = next_val_pair_set.union(org_val_pair_set)
                if(len(next_val_pair_set) > (min_num_val - 1)):
                  inverted_sim_dict[next_val_sim] = set([lim_exceed_txt])
                else:
                  inverted_sim_dict[next_val_sim] = next_val_pair_set
          
          else:
            break
          
          #if(lim_exceed_txt in sim_val_pair_set):
          #  break
        
        inverted_sim_dict[val_sim] = sim_val_pair_set
        
      plain_val_vul_list = []
      
      for sim_val, similar_val_pair_set in inverted_sim_dict.iteritems():
        
        if(lim_exceed_txt not in similar_val_pair_set):
          
          if(len(similar_val_pair_set) <= (min_num_val - 1)):
            org_val_pair_set = org_sim_val_dict[sim_val]
          
            for enc_val_pair in org_val_pair_set:
              enc_val_vul_list.append((enc_val_pair, sim_val))

      enc_val_vul_dict[attr_num] = (enc_val_vul_list, num_unique_val_pairs)  
    
    return enc_val_vul_dict
  
  # ---------------------------------------------------------------------------
  
  def calc_sim_assign(self, enc_val_vul_dict, plain_val_vul_dict, 
                      enc_val_q_tuple_dict):
    
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    
    tolerance_val = float(tolerance_val)/100
    
    enc_assign_val_dict = {}
    
    for attr_num in enc_val_vul_dict.keys():
      
      attr_q_tuple_dict = enc_val_q_tuple_dict[attr_num]
      
      vul_enc_plain_val_list = []
      corr_vul_enc_plain_val_list = []
      
      enc_val_vul_list, enc_num_unique_val = enc_val_vul_dict[attr_num]
      plain_val_vul_list, plain_num_unique_val = plain_val_vul_dict[attr_num]
      
      sorted_enc_val_vul_list = sorted(enc_val_vul_list, key = lambda t:t[1], reverse=True)
      sorted_plain_val_vul_list = sorted(plain_val_vul_list, key = lambda t:t[1], reverse=True)
      
      for enc_val_pair, enc_sim in sorted_enc_val_vul_list:
        
        similar_sim_val_dict = {}
        
        for plain_val_pair, plain_sim in sorted_plain_val_vul_list:
          
          if(abs(enc_sim - plain_sim) <= tolerance_val):
            similar_sim_val_dict[plain_val_pair] = plain_sim
            
          else:
            if(enc_sim - plain_sim > tolerance_val):
              break
        
        if(1 <= len(similar_sim_val_dict) <= (min_num_val - 1)):
          vul_enc_plain_val_list.append((enc_val_pair, enc_sim, similar_sim_val_dict))
          
          enc_plain_val_set1 = attr_q_tuple_dict[enc_val_pair[0]]
          enc_plain_val_set2 = attr_q_tuple_dict[enc_val_pair[1]]
          
          #sim_plain_val_set = set()
          for plain_val_pair in similar_sim_val_dict.keys():
            #sim_plain_val_set.add(plain_val_pair[0])
            #sim_plain_val_set.add(plain_val_pair[1])
            
            plain_val_q_set_1 = set(plain_val_pair[0])
            plain_val_q_set_2 = set(plain_val_pair[1])
            
            q_set_1_in = False
            q_set_2_in = False
            for enc_q_tuple in enc_plain_val_set1:
              if(plain_val_q_set_1 == set(enc_q_tuple)):
                q_set_1_in = True
              if(plain_val_q_set_2 == set(enc_q_tuple)):
                q_set_2_in = True
            
            for enc_q_tuple in enc_plain_val_set2:
              if(plain_val_q_set_1 == set(enc_q_tuple)):
                q_set_1_in = True
              if(plain_val_q_set_2 == set(enc_q_tuple)):
                q_set_2_in = True
            
            if(q_set_1_in and q_set_2_in):
              corr_vul_enc_plain_val_list.append((enc_val_pair, enc_sim, similar_sim_val_dict))
              break
          
          #sim_plain_val_set = set()
          
          #if(len(enc_plain_val_set1 & sim_plain_val_set) > 0 and 
          #   len(enc_plain_val_set2 & sim_plain_val_set) > 0):
          #  corr_vul_enc_plain_val_list.append((enc_val_pair, enc_sim, similar_sim_val_dict))
      
      enc_assign_val_dict[attr_num] = (vul_enc_plain_val_list, corr_vul_enc_plain_val_list,
                                       enc_num_unique_val)
              
    return enc_assign_val_dict
  
  # ---------------------------------------------------------------------------
  '''
  def calc_sim_neigh_vulner(self, enc_neigh_pair_sim_dict):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    normalise = self.normalise
      
    # Calculate the vulneravbility of encoded values
    enc_val_vul_dict = {}
   
    for attr_num, val_neigh_pair_sim_dict in enc_neigh_pair_sim_dict.iteritems():
    
      enc_val_vul_list = []
    
      print 'Attribute number: ', attr_num
    
      sorted_sim_neigh_val_list = sorted(val_neigh_pair_sim_dict.items(), 
                                     key = lambda t: t[1], reverse=True)
      
      #sorted_sim_neigh_val_list = tuple(sorted_sim_neigh_val_list)
      
      sorted_sim_neigh_val_dict = {}
      
      for i, val in enumerate(sorted_sim_neigh_val_list):
        sorted_sim_neigh_val_dict[i] = val
      
      print len(sorted_sim_neigh_val_list)
        
      num_unique_val_pairs = len(sorted_sim_neigh_val_list)
      
      if(tolerance_val > 0):
        all_sim_val_list = val_neigh_pair_sim_dict.values()
        min_val = min(all_sim_val_list)
        max_val = max(all_sim_val_list)
        
        tolerance_val = (float(tolerance_val)/100)*(max_val - min_val)
       
      print 'Attribute Number:', attr_num
      for val_pair, val_sim in sorted_sim_neigh_val_list[:3]:
        print '  Encoded value pair/ similarity: (%s, %s) / %.4f' \
                                %(val_pair[0][:15], val_pair[1][:15], val_sim)
    
      print '  ...'
      print '  ...'
      print '  ...'
  
      for val_pair, val_sim in sorted_sim_neigh_val_list[-3:]:
        print '  Encoded value pair/ similarity: (%s, %s) / %.4f' \
                                %(val_pair[0][:15], val_pair[1][:15], val_sim)
    
      start_index = 0
      
#===============================================================================
#       while(len(sorted_sim_neigh_val_list) > start_index):
#       
#         val_pair, val_sim = sorted_sim_neigh_val_dict[start_index]
#     
#         similar_val_sim_dict = {}
# 
#         for next_index in range(start_index+1, len(sorted_sim_neigh_val_list)):
#           
#           next_val_pair, next_val_sim = sorted_sim_neigh_val_dict[next_index]
#       
#           sim_diff = val_sim - next_val_sim
#        
#           if(sim_diff <= tolerance_val):
#             similar_val_sim_dict[next_val_pair] = next_val_sim
#             start_index += 1
#          
#           else:
#             break
#           
#           if(len(similar_val_sim_dict) > min_num_val):
#             break
#     
#         if(len(similar_val_sim_dict) <= (min_num_val - 1)):
#       
#           enc_val_vul_list.append((val_pair, val_sim))
#        
#           if(len(similar_val_sim_dict) > 0):
#             for s_val_pair, s_val_sim in similar_val_sim_dict.iteritems():
#               enc_val_vul_list.append((s_val_pair, s_val_sim))
#     
#         start_index += 1
#===============================================================================
    
      while(len(sorted_sim_neigh_val_list) > start_index):
       
        val_pair, val_sim = sorted_sim_neigh_val_list[start_index]
     
        similar_val_sim_dict = {}
 
        for next_val_pair, next_val_sim in sorted_sim_neigh_val_list[start_index+1:]:
       
          sim_diff = val_sim - next_val_sim
        
          if(sim_diff <= tolerance_val):
            similar_val_sim_dict[next_val_pair] = next_val_sim
            start_index += 1
          
          else:
            break
           
          if(len(similar_val_sim_dict) > min_num_val):
            break
     
        if(len(similar_val_sim_dict) <= (min_num_val - 1)):
       
          enc_val_vul_list.append((val_pair, val_sim))
        
          if(len(similar_val_sim_dict) > 0):
            for s_val_pair, s_val_sim in similar_val_sim_dict.iteritems():
              enc_val_vul_list.append((s_val_pair, s_val_sim))
     
        start_index += 1
    
      enc_val_vul_dict[attr_num] = (enc_val_vul_list, num_unique_val_pairs)
    
    return enc_val_vul_dict
  
  '''
  # ---------------------------------------------------------------------------
  
  def calc_neigh_vulner(self, sim_neigh_blck_dict, sim_neigh_vec_dict):
  
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    normalise = self.normalise
    
    tolerance_val = float(tolerance_val)/100
    
    lim_exceed_txt = 'min_num_val_reached'
      
    # Calculate the vulneravbility of encoded values
    enc_val_vul_dict = {}
  
    for attr_num, attr_sim_neigh_blck_dict in sim_neigh_blck_dict.iteritems():
      
      uniqe_val_set = set()
      vul_val_dict = {}
      
      print 'Attribute number: ', attr_num
    
      attr_sim_neigh_vec_dict = sim_neigh_vec_dict[attr_num]
    
      for blck_key_set in attr_sim_neigh_blck_dict.values():
        
        uniqe_val_set = uniqe_val_set.union(blck_key_set)
        
        all_key_pairs = itertools.combinations(blck_key_set, 2)
      
        for val_key1, val_key2 in all_key_pairs:
          
          sim_neigh_feat_vec1 = attr_sim_neigh_vec_dict[val_key1]
          sim_neigh_feat_vec2 = attr_sim_neigh_vec_dict[val_key2]
          
          # Calculate the Cosine similarity beween the featue vectors
          #
          vec_len1 = math.sqrt(numpy.dot(sim_neigh_feat_vec1, sim_neigh_feat_vec1))
          vec_len2 = math.sqrt(numpy.dot(sim_neigh_feat_vec2, sim_neigh_feat_vec2))
          cosine = numpy.dot(sim_neigh_feat_vec1,sim_neigh_feat_vec2) / vec_len1 / vec_len2
          cos_distance = math.acos(min(cosine,1.0)) / math.pi
      
          if(cos_distance <= tolerance_val):
            sim_val_set1 = vul_val_dict.get(val_key1, set())
            sim_val_set2 = vul_val_dict.get(val_key2, set())
            
            if(lim_exceed_txt not in sim_val_set1):
              sim_val_set1.add(val_key2)
              
              if(len(sim_val_set1) > (min_num_val - 1)):
                sim_val_set1 = set([lim_exceed_txt])
            
            if(lim_exceed_txt not in sim_val_set2):
              sim_val_set2.add(val_key1)
              
              if(len(sim_val_set2) > (min_num_val - 1)):
                sim_val_set2 = set([lim_exceed_txt])
            
            
            vul_val_dict[val_key1] = sim_val_set1
            vul_val_dict[val_key2] = sim_val_set2
          
          else:
            if(val_key1 not in vul_val_dict):
              vul_val_dict[val_key1] = set()
            
            if(val_key2 not in vul_val_dict):
              vul_val_dict[val_key2] = set()
        
      enc_val_vul_list = []
      
      for val_key, sim_val_set in vul_val_dict.iteritems():
        
        if(lim_exceed_txt not in sim_val_set):
          if(len(sim_val_set) <= (min_num_val - 1)):
            sim_neigh_feat_vec = attr_sim_neigh_vec_dict[val_key]
            enc_val_vul_list.append((val_key, sim_neigh_feat_vec))
        
      num_unique_val = len(uniqe_val_set)  
      enc_val_vul_dict[attr_num] = (enc_val_vul_list, num_unique_val)  

    return enc_val_vul_dict
  
# ---------------------------------------------------------------------------
  
  def calc_sim_neigh_assign(self, enc_val_vul_dict, plain_val_vul_dict, 
                            enc_val_q_tuple_dict):
    
    tolerance_val = self.tolerance_val
    min_num_val = self.min_num_val
    enc_method = self.enc_method
    
    tolerance_val = float(tolerance_val)/100
    
    enc_assign_val_dict = {}
    
    for attr_num in enc_val_vul_dict.keys():
      
      attr_q_tuple_dict = enc_val_q_tuple_dict[attr_num]
      
      vul_enc_plain_val_list = []
      corr_vul_enc_plain_val_list = []
      
      enc_val_vul_list, enc_num_unique_val = enc_val_vul_dict[attr_num]
      plain_val_vul_list, plain_num_unique_val = plain_val_vul_dict[attr_num]
      
      sorted_enc_val_vul_list = sorted(enc_val_vul_list, \
                                       key = lambda t:numpy.mean(t[1]), reverse=True)
      sorted_plain_val_vul_list = sorted(plain_val_vul_list, \
                                         key = lambda t:numpy.mean(t[1]), reverse=True)
      
      for enc_val_key, enc_feat_vec in sorted_enc_val_vul_list:
        
        similar_sim_val_dict = {}
        
        for plain_val_key, plain_feat_vec in sorted_plain_val_vul_list:
          
          # Calculate the Cosine similarity beween the featue vectors
          #
          vec_len1 = math.sqrt(numpy.dot(enc_feat_vec, enc_feat_vec))
          vec_len2 = math.sqrt(numpy.dot(plain_feat_vec, plain_feat_vec))
          cosine = numpy.dot(enc_feat_vec,plain_feat_vec) / vec_len1 / vec_len2
          cos_distance = math.acos(min(cosine,1.0)) / math.pi
          
          
          #if(abs(enc_sim - plain_sim) <= tolerance_val):
          #  similar_sim_val_dict[plain_val_pair] = plain_sim
            
          #else:
          #  if(enc_sim - plain_sim > tolerance_val):
          #    break
          
          if(cos_distance <= tolerance_val):
            similar_sim_val_dict[plain_val_key] = plain_feat_vec
            
          else:
            break         
          
        
        if(1 <= len(similar_sim_val_dict) <= (min_num_val - 1)):
          vul_enc_plain_val_list.append((enc_val_key, enc_feat_vec, similar_sim_val_dict))
          
          enc_q_tuple_set = attr_q_tuple_dict[enc_val_key]
          plain_q_set_in = False
          
          for plain_val_key in similar_sim_val_dict.keys():
            for enc_q_tuple in enc_q_tuple_set:
              
              if(set(plain_val_key) == set(enc_q_tuple)):
                plain_q_set_in = True
                break
            
            if(plain_q_set_in):
              corr_vul_enc_plain_val_list.append((enc_val_key, enc_feat_vec, similar_sim_val_dict))
              break
      
      enc_assign_val_dict[attr_num] = (vul_enc_plain_val_list, corr_vul_enc_plain_val_list,
                                       enc_num_unique_val)
              
    return enc_assign_val_dict
  
# =============================================================================
# Additional functions

def get_qid_val(rec_val_dict, attr_num_list):
  
  ignore_val = 'removed'
  
  num_remove = 0
  
  qid_val_dict = {}
  
  for rec_id, rec_val_list in rec_val_dict.iteritems():
    
    rec_qid_dict = {}
    
    for attr_num in attr_num_list:
      qid_val = rec_val_list[attr_num]
      qid_val_set = set([qid_val])
      
      if(ignore_val in qid_val_set):
        qid_val_set.remove(ignore_val)
        num_remove += 1
      
      rec_qid_dict[attr_num] = qid_val_set
      
    qid_val_dict[rec_id] = rec_qid_dict
  
  print 'Number of removed values', num_remove
  
  return qid_val_dict
  
# ---------------------------------------------------------------------------

def get_token(rec_val_dict, attr_num_list):
  
  token_dict = {}
  
  ignore_val = 'removed'
  
  for rec_id, rec_val_list in rec_val_dict.iteritems():
    
    rec_token_dict = {}
    
    for attr_num in attr_num_list:
      qid_val = rec_val_list[attr_num]
      qid_token_set = set(qid_val.split(" "))
      
      if(ignore_val in qid_token_set):
        qid_token_set.remove(ignore_val)
      
      rec_token_dict[attr_num] = qid_token_set
      
    token_dict[rec_id] = rec_token_dict
  
  return token_dict 
  
# ---------------------------------------------------------------------------

def get_token_substring(rec_val_dict, attr_num_list, q_len, padded_flag):
  
  q_gram_dict = {}
  
  ignore_val = 'removed'
  
  for rec_id, rec_val_list in rec_val_dict.iteritems():
    
    rec_q_gram_dict = {}
    
    for attr_num in attr_num_list:
      qid_val = rec_val_list[attr_num]
      
      if(qid_val != ignore_val):
        qid_q_gram_set = gen_q_grams(qid_val, q_len, padded_flag)
      else:
        qid_q_gram_set = set()
      
      rec_q_gram_dict[attr_num] = qid_q_gram_set
      
    q_gram_dict[rec_id] = rec_q_gram_dict
  
  return q_gram_dict

# ---------------------------------------------------------------------------
    
def gen_q_grams(attr_val, q, padded_flag):
  
  PAD_CHAR = chr(1)   # Used for q-gram padding
  
  qm1 = q-1

  attr_val_str = attr_val.strip()

  if (padded_flag == True):  # Add padding start and end characters
    attr_val_str = PAD_CHAR*qm1+attr_val_str+PAD_CHAR*qm1
  
  attr_val_len = len(attr_val_str)

  # Convert into q-grams and process them
  #
  attr_q_gram_list = [attr_val_str[i:i+q] for i in range(attr_val_len - qm1)]
  attr_q_gram_set = set(attr_q_gram_list)

  return attr_q_gram_set 
  
# ---------------------------------------------------------------------------

def min_max_normalise(val_dict, vul_type):
  
  norm_val_dict = {}
  
  for attr_num in val_dict.keys():
    val_charac_dict = val_dict[attr_num]
    
    new_val_dict = {}
    
    if(vul_type in ['freq', 'cooccur']):
      all_freq_val_list = val_charac_dict.values()
      min_val = min(all_freq_val_list)
      max_val = max(all_freq_val_list)
      
      for key, val in val_charac_dict.iteritems():
        if(max_val - min_val == 0):
          norm_val = val
        else:
          norm_val = float(val - min_val)/(max_val - min_val)
        new_val_dict[key] = norm_val
      
    else: #vul_type = 'len'
      all_len_val_list = val_charac_dict.keys()
      min_val = min(all_len_val_list)
      max_val = max(all_len_val_list)
      
      val_norm_val_dict = {}
      
      for key, val in val_charac_dict.iteritems():
        norm_key = float(key - min_val)/(max_val - min_val)
        new_val_dict[norm_key] = val
        val_norm_val_dict[key] = norm_key
    
    norm_val_dict[attr_num] = new_val_dict
    
  if(vul_type in ['freq', 'cooccur']):
    return norm_val_dict
  else:
    return norm_val_dict, val_norm_val_dict

# ---------------------------------------------------------------------------

def calc_neigh_pair_sim(sim_neigh_blck_dict, sim_neigh_vec_dict):
    
  plain_sim_neigh_dict = {}
  sim_calc_time_dict = {}
  
  for attr_num, attr_sim_neigh_blck_dict in sim_neigh_blck_dict.iteritems():
    
    start_time = time.time()
    
    attr_sim_neigh_vec_dict = sim_neigh_vec_dict[attr_num]
    
    attr_sim_neigh_dict = {}
    
    for blck_key_set in attr_sim_neigh_blck_dict.values():
        
      all_key_tuple_pairs = itertools.combinations(blck_key_set, 2)
      
      for key_tuple1, key_tuple2 in all_key_tuple_pairs:
        
        sim_neigh_feat_vec1 = attr_sim_neigh_vec_dict[key_tuple1]
        sim_neigh_feat_vec2 = attr_sim_neigh_vec_dict[key_tuple2]
        
        # Calculate the Cosine similarity beween the featue vectors
        #
        vec_len1 = math.sqrt(numpy.dot(sim_neigh_feat_vec1, sim_neigh_feat_vec1))
        vec_len2 = math.sqrt(numpy.dot(sim_neigh_feat_vec2, sim_neigh_feat_vec2))
        cosine = numpy.dot(sim_neigh_feat_vec1,sim_neigh_feat_vec2) / vec_len1 / vec_len2
        cos_sim = 1.0 - math.acos(min(cosine,1.0)) / math.pi
        
        for key_pair in itertools.product(key_tuple1, key_tuple2):
          
          if(key_pair not in attr_sim_neigh_dict):
            attr_sim_neigh_dict[key_pair] = cos_sim
          else:
            assert cos_sim == attr_sim_neigh_dict[key_pair]
    
    calc_time = time.time() - start_time
    
    plain_sim_neigh_dict[attr_num] = attr_sim_neigh_dict
    sim_calc_time_dict[attr_num] = calc_time
          
  return plain_sim_neigh_dict, sim_calc_time_dict

# ---------------------------------------------------------------------------

def calc_enc_neigh_pair_sim(sim_neigh_blck_dict, sim_neigh_vec_dict):
    
  plain_sim_neigh_dict = {}
  sim_calc_time_dict = {}
  
  for attr_num, attr_sim_neigh_blck_dict in sim_neigh_blck_dict.iteritems():
    
    start_time = time.time()
    
    attr_sim_neigh_vec_dict = sim_neigh_vec_dict[attr_num]
    
    attr_sim_neigh_dict = {}
    
    for blck_key_set in attr_sim_neigh_blck_dict.values():
        
      all_key_tuple_pairs = itertools.combinations(blck_key_set, 2)
      
      for key_tuple1, key_tuple2 in all_key_tuple_pairs:
        
        sim_neigh_feat_vec1 = attr_sim_neigh_vec_dict[key_tuple1]
        sim_neigh_feat_vec2 = attr_sim_neigh_vec_dict[key_tuple2]
        
        # Calculate the Cosine similarity beween the featue vectors
        #
        vec_len1 = math.sqrt(numpy.dot(sim_neigh_feat_vec1, sim_neigh_feat_vec1))
        vec_len2 = math.sqrt(numpy.dot(sim_neigh_feat_vec2, sim_neigh_feat_vec2))
        cosine = numpy.dot(sim_neigh_feat_vec1,sim_neigh_feat_vec2) / vec_len1 / vec_len2
        cos_sim = 1.0 - math.acos(min(cosine,1.0)) / math.pi
        
        key_pair = (key_tuple1, key_tuple2)
          
        if(key_pair not in attr_sim_neigh_dict):
          attr_sim_neigh_dict[key_pair] = cos_sim
        else:
          assert cos_sim == attr_sim_neigh_dict[key_pair]
    
    calc_time = time.time() - start_time
    
    plain_sim_neigh_dict[attr_num] = attr_sim_neigh_dict
    sim_calc_time_dict[attr_num] = calc_time
          
  return plain_sim_neigh_dict, sim_calc_time_dict

# ---------------------------------------------------------------------------
